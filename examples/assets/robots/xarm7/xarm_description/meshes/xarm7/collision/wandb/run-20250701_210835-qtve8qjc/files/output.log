GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name  | Type           | Params
-----------------------------------------
0 | model | SequentialFlow | 3.2 M
-----------------------------------------
3.2 M     Trainable params
0         Non-trainable params
3.2 M     Total params
12.936    Total estimated model params size (MB)
[34m[1mwandb[0m: [33mWARNING[0m The project_name method is deprecated and will be removed in a future release. Please use `run.project` instead.
Validation sanity check:   0%|                                                                   | 0/1 [00:00<?, ?it/s]Module warp.sim.articulation load took 0.25 ms
/home/ps/anaconda3/envs/node_ik/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/ps/anaconda3/envs/node_ik/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:227: UserWarning: You called `self.log('test_set_size', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.
  warning_cache.warn(
/home/ps/anaconda3/envs/node_ik/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:227: UserWarning: You called `self.log('samples_per_endpoint', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.
  warning_cache.warn(
Epoch 82:   7%| | 33/501 [00:40<09:28,  1.21s/it, loss=-2.3, v_num=8qjc, train_loss_step=-1.89, val_loss=-1.90, train_l
/home/ps/anaconda3/envs/node_ik/lib/python3.8/site-packages/pytorch_lightning/trainer/data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 24 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
                                                                                                                       
/home/ps/anaconda3/envs/node_ik/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:688: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...
  rank_zero_warn("Detected KeyboardInterrupt, attempting graceful shutdown...")
